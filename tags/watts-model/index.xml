<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>watts model on Daniel Chen</title>
    <link>/tags/watts-model/</link>
    <description>Recent content in watts model on Daniel Chen</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Daniel Chen {year}</copyright>
    <lastBuildDate>Thu, 30 Mar 2017 00:10:00 +0000</lastBuildDate>
    
	    <atom:link href="/tags/watts-model/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A &#39;Simple&#39; Neural-Network Model</title>
      <link>/2017/03/30/a-simple-neural-network-model/</link>
      <pubDate>Thu, 30 Mar 2017 00:10:00 +0000</pubDate>
      
      <guid>/2017/03/30/a-simple-neural-network-model/</guid>
      <description>

&lt;p&gt;My previous &lt;a href=&#34;http://chendaniely.github.io/research/2016/09/29/expanding_watts_to_lens/&#34; target=&#34;_blank&#34;&gt;blog post&lt;/a&gt; summarized the main points of the &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/16578874&#34; target=&#34;_blank&#34;&gt;Watts 2002 paper&lt;/a&gt;.
At the very end of the post I mentioned ways we can extend the Watts model with neural-networks.
Here I outline the steps of the neural-network simulation.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;Generally the model goes though an initiation step, a simulation step, and a cleanup step.
In the initiation step, the agents are created and connected in a network.
Then selected agents are seeded with a value before continuing onto the simulation step.
In the simulation step, &amp;lsquo;steps&amp;rsquo; for each time tick are performed.
This includes picking agents to be updated, making the necessary calculations for an update,
and updating agents in a simultaneous or sequential manner.
Agent states in teach time tick is saved to be written to a (CSV) file.
The cleanup step is mainly there when programming the model.
It saves any unwritten states to the file, and
any other related tasks of that nature.&lt;/p&gt;

&lt;h1 id=&#34;mann&#34;&gt;MANN&lt;/h1&gt;

&lt;p&gt;The neural networks used in MANN use the &lt;a href=&#34;http://web.stanford.edu/group/mbc/LENSManual/&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;the light, efficient network simulator&amp;rdquo; (LENS)&lt;/a&gt;.
I created a (inefficient) python wrapper around LENS, &lt;a href=&#34;https://github.com/chendaniely/pylens&#34; target=&#34;_blank&#34;&gt;pylens&lt;/a&gt;.
This mainly stems from the fact my advisor used LENS for his work in the past,
and interface with it via the command line with input files.
The inefficient stems from the fact that I am having python write our the necessary input files for the neural network,
and making command-line &lt;code&gt;subprocess&lt;/code&gt; calls to LENS.&lt;/p&gt;

&lt;h2 id=&#34;initiation&#34;&gt;Initiation&lt;/h2&gt;

&lt;p&gt;$n$ agents are created for the model.
When an agent is created, a feed-forward neural network with randomized weights to represent its state.
A prototype that will be used to train the neural network is assigned to the agent.&lt;/p&gt;

&lt;p&gt;The agent&amp;rsquo;s will all be connected to a network.
For example in the &lt;code&gt;networkx&lt;/code&gt; list of graph generators,
the [&lt;code&gt;fast_gnp_random_graph&lt;/code&gt;][5] takes the number of agents, $n$,
and a probability, $p$, of an edge being created.&lt;/p&gt;

&lt;p&gt;To train the neural network, it needs a set of example files to train.
The example file consists of $k$ (50) examples.
Each example is a randomized form of the prototype.
The amount of randomization is determined by parameter $\delta$.
To incorporate heterogeneity in the model,
we also mutate the prototype that is used to create the example files.
This mutation rate is designated as $\epsilon$.&lt;/p&gt;

&lt;p&gt;How well the agent gets trained is parameterized with the &lt;em&gt;criterion&lt;/em&gt; variable.
It is analogous to the amount of error the neural network can make before it finishes training.
That is, the smaller the criterion, the smaller the error, the more accurate it can represent the training set.
All agents stop training after 1000 epochs (training cycles for the neural network).&lt;/p&gt;

&lt;p&gt;Once the neural network is trained, its weights are output to a file to be loaded during the simulation step.&lt;/p&gt;

&lt;p&gt;All agents begin with a state of 0.
That is the first layer of the neural network all have values of 0.
We then select agents to be seeded.
The seeded agent is presented (via an example file) the non-$\epsilon$-mutated prototype.
We cycle this value through the neural network with one epoch,
and the output of the neural network is assigned to the agent&amp;rsquo;s state.&lt;/p&gt;

&lt;p&gt;We then begin the simulation part of the model.&lt;/p&gt;

&lt;h2 id=&#34;simulation&#34;&gt;Simulation&lt;/h2&gt;

&lt;p&gt;The simulation runs in &lt;em&gt;steps&lt;/em&gt;.
These steps designate the amount of &lt;em&gt;time ticks&lt;/em&gt; the simulation runs for.
The same process occurs during each time tick until the simulation ends.&lt;/p&gt;

&lt;p&gt;All agents will be randomly selected (without replacement) to undergo an update process.
The update process looks at all the agent&amp;rsquo;s neighbors with a directed edge coming &lt;em&gt;into&lt;/em&gt; the selected agent
(i.e., neighbors or predecessors),
and randomly selects one of the agents to be the &lt;em&gt;influencer&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The influencer writes our its current state as an example file.
This example file is used by the agent&amp;rsquo;s neural network and the output is assigned as the agent&amp;rsquo;s new state.&lt;/p&gt;

&lt;p&gt;In a sequential update process,
the agent&amp;rsquo;s new state is assigned as described above.
However, during simultaneous updating,
the new state will be stored into a temporary state value,
so that if the agent is used as an influencer to another agent,
the original agent state value will be written out to the example file.
In simultaneous updating, only after all agents have undergone the update process will they
assign the temporary state as their new state.&lt;/p&gt;

&lt;p&gt;The agent states are saved to a file at the end of the initiation step and the
end of each simulation time tick.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Expanding the Watts Model</title>
      <link>/2016/09/29/expanding-the-watts-model/</link>
      <pubDate>Thu, 29 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/09/29/expanding-the-watts-model/</guid>
      <description>

&lt;p&gt;I wrote a &lt;a href=&#34;http://chendaniely.github.io/research/2016/08/31/a_simple_model_of_global_cascades_on_random_networks/&#34; target=&#34;_blank&#34;&gt;blog post&lt;/a&gt; and
gave a &lt;a href=&#34;www.google.com&#34; target=&#34;_blank&#34;&gt;seminar talk&lt;/a&gt; about the &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/16578874&#34; target=&#34;_blank&#34;&gt;Watts 2002 paper&lt;/a&gt;.
The next step is thinking about expanding the &lt;em&gt;binary decisions with externalities&lt;/em&gt; model to a
&lt;em&gt;psychological plausible decisions with externalities&lt;/em&gt; model.
This has been the goal of the &lt;a href=&#34;https://github.com/chendaniely/mann2&#34; target=&#34;_blank&#34;&gt;multi-agent neural-network (MANN) project&lt;/a&gt;.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h1 id=&#34;context-from-the-watts-model&#34;&gt;Context from the Watts model&lt;/h1&gt;

&lt;p&gt;From an information diffusion perspective,
a cascade is the spread of information from an initial set (seed) of individuals (nodes).
Watts talks about features of a network that create a &lt;em&gt;global cascade&lt;/em&gt;,
which is simply a cascade of &amp;lsquo;sufficient&amp;rsquo; size.
The ability for a node to receive and pass on a bit of information is it&amp;rsquo;s &lt;em&gt;vulnerability&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Cascades are triggered by the interaction between 2 properties &amp;ndash;
a network property (degree centrality) and a node property (threshold).
If we look at these 2 properties as mutually exclusive from one another,
then nodes with smaller degree centrality will be less vulnerable compared to nodes with higher degree centrality,
and nodes with lower threshold values will be more vulnerable than nodes with higher threshold values.
This is because nodes with fewer connections have a smaller probability of getting information passed onto it,
and nodes with lower thresholds need fewer bits of information to propagate a signal.&lt;/p&gt;

&lt;p&gt;Although degree centrality (&lt;em&gt;local dependencies&lt;/em&gt;) and &lt;em&gt;(fractional) thresholds&lt;/em&gt; are integral parts of
the binary decisions with externalities model,
another key aspect is &lt;em&gt;heterogeneity&lt;/em&gt;.
For a given network, not every node will have the same degree centrality,
and not every node will have the same fractional threshold value.
As a matter of fact, any combination of high/low degree centrality and high/low fractional threshold is possible,
and each combination has an effect on a particular node&amp;rsquo;s vulnerability.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Degree (k)&lt;/th&gt;
&lt;th&gt;Threshold ($\phi$)&lt;/th&gt;
&lt;th&gt;Vulnerability&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Low&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Low&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Low&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Low&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Low&lt;/td&gt;
&lt;td&gt;Low&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;expanding-the-watts-model-with-neural-networks&#34;&gt;Expanding the Watts model with neural networks&lt;/h1&gt;

&lt;p&gt;The next step is to explore ways the Watts model can be expanded.
The rationale being decisions, and similarly, behaviors, are binary,
but the process of making a decision and performing an action are not.
&lt;a href=&#34;http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0062490&#34; target=&#34;_blank&#34;&gt;Mark Orr, Roxanne Thrush, and David C. Plaut&lt;/a&gt;
suggest incorporating the &lt;a href=&#34;https://en.wikipedia.org/wiki/Theory_of_reasoned_action&#34; target=&#34;_blank&#34;&gt;Theory of Reasoned Action (TRA)&lt;/a&gt; as the
theoretical framework to describe how behaviors emerge and an
&lt;a href=&#34;https://en.wikipedia.org/wiki/Autoassociative_memory&#34; target=&#34;_blank&#34;&gt;auto&lt;/a&gt;-&lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/009813549280051A&#34; target=&#34;_blank&#34;&gt;associator&lt;/a&gt; &lt;a href=&#34;https://en.wikipedia.org/wiki/Artificial_neural_network&#34; target=&#34;_blank&#34;&gt;neural-network&lt;/a&gt;
as the computational framework to simulate nodes.&lt;/p&gt;

&lt;p&gt;A neural network allows for a multi-dimensional node, not just a simple binary node.
The key feature of an &lt;em&gt;auto associative neural network&lt;/em&gt; is its ability to learn and reproduce an identity (a.k.a, prototype) given a portion of inputs.
From the Wikipedia &lt;a href=&#34;https://en.wikipedia.org/wiki/Autoassociative_memory&#34; target=&#34;_blank&#34;&gt;page&lt;/a&gt;, if we are presented the quote &amp;ldquo;I came, I saw&amp;hellip;&amp;rdquo;,
we should be able to complete the rest of the quote: &amp;ldquo;&amp;hellip; I conquered&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;If we re-conceptualize the Watts model, the prototype is the bit of information each node can pass to its neighbors (i.e., a state of 1).
Since this is a binary model, then each node can be thought to be trained to have an output of 1,
but has a state of 0 until the proper inputs are met (local dependencies and fractional thresholds), and the node has a state of 1.&lt;/p&gt;

&lt;p&gt;From the neural network perspective, every node is trained to a particular prototype (e.g., the vector: &lt;code&gt;[1, 1, 1, 0, 0, 0]&lt;/code&gt;),
and has a state of 0 (e.g., the vector: &lt;code&gt;[0, 0, 0, 0, 0, 0]&lt;/code&gt;)
until proper inputs are met, the neural network will output the prototype (e.g., the vector: &lt;code&gt;[1, 1, 1, 0, 0, 0]&lt;/code&gt;).
Additionally, the same output should be returned, if only a portion of the prototype vector is presented.&lt;/p&gt;

&lt;h2 id=&#34;creating-a-neural-network-model-analogous-to-the-watts-model&#34;&gt;Creating a neural network model analogous to the Watts model&lt;/h2&gt;

&lt;p&gt;While there are many questions and solutions on how to relate the Watts model to this newly defined neural-network model,
two immediately come to mind.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;How do we measure if information has been passed from one node to another?&lt;/li&gt;
&lt;li&gt;How do we map fractional thresholds between the two models?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Since we know the trained/learned prototype for each node,
one way to know if information passed from the seed node (and subsequent nodes) to a new node is to look at how &amp;lsquo;similar&amp;rsquo;
the output of the new node is to the prototype.
Similarity can be measured in many ways, one such way is to use &lt;a href=&#34;https://en.wikipedia.org/wiki/Cosine_similarity&#34; target=&#34;_blank&#34;&gt;cosine similarity&lt;/a&gt;.
Once the similarity is calculated, we can apply another threshold, $\theta$,
that signals the propagation of information.
This new threshold can be used to calculate a binary state, $S_1$ that is analogous to the Watts model state, $S_0$.
We can use $\theta$ to calculate how many nodes are different from the node of interest
(this can also be thought of as some function of $S_1$),
and use the same threshold, $\phi$, from the Watts model to determine whether the node of interest will propagate our signal in the network.&lt;/p&gt;

&lt;p&gt;However, since our definition of &amp;lsquo;similarity&amp;rsquo; and &amp;lsquo;information propagation&amp;rsquo; relies on the &lt;em&gt;output&lt;/em&gt; of our neural network,
we need to give the neural network a set of &lt;em&gt;inputs&lt;/em&gt;.
This leads to anther question:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;How do we provide inputs to nodes that have been designated to carry and propagate information in the network?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We can do this a few ways.
For each node that will propagate information we can assign the input as&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;the prototype (e.g., the vector: &lt;code&gt;[1, 1, 1, 0, 0, 0]&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;the state (a.k.a output) of 1 of the &amp;lsquo;different&amp;rsquo; connected nodes&lt;/li&gt;
&lt;li&gt;the average state of all of the &amp;lsquo;different&amp;rsquo; connected nodes&lt;/li&gt;
&lt;li&gt;the average state of all connected nodes&lt;/li&gt;
&lt;li&gt;present each &amp;lsquo;different&amp;rsquo; node in a random order and have the neural network cycle though them&lt;/li&gt;
&lt;li&gt;present all connected nodes in a random order and have the neural network cycle though them&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Other than the first option of using the prototype,
the other methods will still preserve the differences in degree centrality between the nodes.
For example, if a node only has one neighbor and it will be updated with 1 neighbor,
it will always be presented with the same inputs.
However if a node has multiple neighbors, the probability of the same neighbor picked every time is proportional to the number neighbors.&lt;/p&gt;

&lt;h2 id=&#34;creating-a-simpler-neural-network-model&#34;&gt;Creating a simpler neural-network model&lt;/h2&gt;

&lt;p&gt;A simpler approach would be to have each node in the network trained against the prototype.
Seed a single node with the prototype, and run the model without any additional thresholding rule ($\theta$),
and have each node use a random 1 neighbor&amp;rsquo;s state (i.e., output) and its input.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
